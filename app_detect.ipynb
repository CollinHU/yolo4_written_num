{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import colorsys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input\n",
    "from core.config import *\n",
    "from core.yolov4 import *\n",
    "\n",
    "YOLO_STRIDES                = [8, 16, 32]\n",
    "STRIDES         = np.array(YOLO_STRIDES)\n",
    "ANCHORS         = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
    "\n",
    "def detect_image(Yolo, image_path, output_path, input_size=416, show=False, \n",
    "                CLASSES=YOLO_COCO_CLASSES, \n",
    "                score_threshold=0.5, iou_threshold=0.5, \n",
    "                rectangle_colors=''):\n",
    "    original_image      = cv2.imread(image_path)\n",
    "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
    "    plt.imshow(image_data)\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "    if YOLO_FRAMEWORK == \"tf\":\n",
    "        pred_bbox = Yolo.predict(image_data, verbose=0)\n",
    "    elif YOLO_FRAMEWORK == \"trt\":\n",
    "        batched_input = tf.constant(image_data)\n",
    "        result = Yolo(batched_input)\n",
    "        pred_bbox = []\n",
    "        for key, value in result.items():\n",
    "            value = value.numpy()\n",
    "            pred_bbox.append(value)\n",
    "        \n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "    #print(pred_bbox)\n",
    "    bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
    "    #print(len(bboxes))\n",
    "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "    #print(bboxes)\n",
    "    bboxes = merge_bboxes(bboxes)\n",
    "\n",
    "    image = draw_bbox(original_image, bboxes, CLASSES=CLASSES,show_label=True, \n",
    "                    show_confidence = False, rectangle_colors=rectangle_colors)\n",
    "    # CreateXMLfile(\"XML_Detections\", str(int(time.time())), original_image, bboxes, read_class_names(CLASSES))\n",
    "\n",
    "    if output_path != '': cv2.imwrite(output_path, image)\n",
    "    if show:\n",
    "        # Show the image\n",
    "        cv2.imshow(\"predicted image\", image)\n",
    "        # Load and hold the image\n",
    "        cv2.waitKey(0)\n",
    "        # To close the window after the required kill value was provided\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    return image, bboxes\n",
    "\n",
    "def postprocess_boxes(pred_bbox, original_image, input_size, score_threshold):\n",
    "    valid_scale=[0, np.inf]\n",
    "    pred_bbox = np.array(pred_bbox)\n",
    "\n",
    "    pred_xywh = pred_bbox[:, 0:4]\n",
    "    pred_conf = pred_bbox[:, 4]\n",
    "    pred_prob = pred_bbox[:, 5:]\n",
    "\n",
    "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
    "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
    "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
    "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
    "    org_h, org_w = original_image.shape[:2]\n",
    "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
    "\n",
    "    dw = (input_size - resize_ratio * org_w) / 2\n",
    "    dh = (input_size - resize_ratio * org_h) / 2\n",
    "\n",
    "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
    "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
    "\n",
    "    # 3. clip some boxes those are out of range\n",
    "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
    "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
    "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))\n",
    "    pred_coor[invalid_mask] = 0\n",
    "\n",
    "    # 4. discard some invalid boxes\n",
    "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
    "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
    "\n",
    "    # 5. discard boxes with low scores\n",
    "    classes = np.argmax(pred_prob, axis=-1)\n",
    "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
    "    score_mask = scores > score_threshold\n",
    "    mask = np.logical_and(scale_mask, score_mask)\n",
    "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
    "\n",
    "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)\n",
    "\n",
    "def bboxes_iou(boxes1, boxes2):\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area    = boxes1_area + boxes2_area - inter_area\n",
    "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
    "\n",
    "    return ious\n",
    "\n",
    "def draw_bbox(image, bboxes, CLASSES=YOLO_COCO_CLASSES, show_label=True, \n",
    "show_confidence = True, Text_colors=(255,255,0), rectangle_colors='', tracking=False):   \n",
    "    NUM_CLASS = read_class_names(CLASSES)\n",
    "    num_classes = len(NUM_CLASS)\n",
    "    image_h, image_w, _ = image.shape\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    #print(\"hsv_tuples\", hsv_tuples)\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
    "        if bbox_thick < 1: bbox_thick = 1\n",
    "        fontScale = 0.75 * bbox_thick\n",
    "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "\n",
    "        # put object rectangle\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick*2)\n",
    "\n",
    "        if show_label:\n",
    "            # get text label\n",
    "            score_str = \" {:.2f}\".format(score) if show_confidence else \"\"\n",
    "\n",
    "            if tracking: score_str = \" \"+str(score)\n",
    "\n",
    "            try:\n",
    "                label = \"{}\".format(NUM_CLASS[class_ind]) + score_str\n",
    "            except KeyError:\n",
    "                print(\"You received KeyError, this might be that you are trying to use yolo original weights\")\n",
    "                print(\"while using custom classes, if using custom model in configs.py set YOLO_CUSTOM_WEIGHTS = True\")\n",
    "\n",
    "            # get text size\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                                                                  fontScale, thickness=bbox_thick)\n",
    "            # put filled text rectangle\n",
    "            cv2.rectangle(image, (x1, y1), (x1 + text_width, y1 - text_height - baseline), bbox_color, thickness=cv2.FILLED)\n",
    "\n",
    "            # put text above rectangle\n",
    "            cv2.putText(image, label, (x1, y1-4), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                        fontScale, Text_colors, bbox_thick, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
    "    \"\"\"\n",
    "    :param bboxes: (xmin, ymin, xmax, ymax, score, class)\n",
    "\n",
    "    Note: soft-nms, https://arxiv.org/pdf/1704.04503.pdf\n",
    "          https://github.com/bharatsingh430/soft-nms\n",
    "    \"\"\"\n",
    "    classes_in_img = list(set(bboxes[:, 5]))\n",
    "    best_bboxes = []\n",
    "\n",
    "    for cls in classes_in_img:\n",
    "        cls_mask = (bboxes[:, 5] == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "        # Process 1: Determine whether the number of bounding boxes is greater than 0 \n",
    "        while len(cls_bboxes) > 0:\n",
    "            # Process 2: Select the bounding box with the highest score according to socre order A\n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
    "            # Process 3: Calculate this bounding box A and\n",
    "            # Remain all iou of the bounding box and remove those bounding boxes whose iou value is higher than the threshold \n",
    "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "\n",
    "            assert method in ['nms', 'soft-nms']\n",
    "\n",
    "            if method == 'nms':\n",
    "                iou_mask = iou > iou_threshold\n",
    "                weight[iou_mask] = 0.0\n",
    "\n",
    "            if method == 'soft-nms':\n",
    "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
    "\n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
    "            score_mask = cls_bboxes[:, 4] > 0.\n",
    "            cls_bboxes = cls_bboxes[score_mask]\n",
    "\n",
    "    return best_bboxes\n",
    "\n",
    "def image_preprocess(image, target_size, gt_boxes=None):\n",
    "    ih, iw    = target_size\n",
    "    h,  w, _  = image.shape\n",
    "\n",
    "    scale = min(iw/w, ih/h)\n",
    "    nw, nh  = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "\n",
    "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
    "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
    "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
    "    image_paded = image_paded / 255.\n",
    "\n",
    "    if gt_boxes is None:\n",
    "        return image_paded\n",
    "\n",
    "    else:\n",
    "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
    "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
    "        return image_paded, gt_boxes\n",
    "\n",
    "def read_class_names(class_file_name):\n",
    "    # loads class name from a file\n",
    "    names = {}\n",
    "    with open(class_file_name, 'r') as data:\n",
    "        for ID, name in enumerate(data):\n",
    "            names[ID] = name.strip('\\n')\n",
    "    return names\n",
    "\n",
    "def decode(conv_output, NUM_CLASS, i=0):\n",
    "    # where i = 0, 1 or 2 to correspond to the three grid scales  \n",
    "    conv_shape       = tf.shape(conv_output)\n",
    "    batch_size       = conv_shape[0]\n",
    "    output_size      = conv_shape[1]\n",
    "\n",
    "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
    "\n",
    "    #conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # offset of center position     \n",
    "    #conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # Prediction box length and width offset\n",
    "    #conv_raw_conf = conv_output[:, :, :, :, 4:5] # confidence of the prediction box\n",
    "    #conv_raw_prob = conv_output[:, :, :, :, 5: ] # category probability of the prediction box\n",
    "    conv_raw_dxdy, conv_raw_dwdh, conv_raw_conf, conv_raw_prob = tf.split(conv_output, (2, 2, 1, NUM_CLASS), axis=-1)\n",
    "\n",
    "    # next need Draw the grid. Where output_size is equal to 13, 26 or 52  \n",
    "    #y = tf.range(output_size, dtype=tf.int32)\n",
    "    #y = tf.expand_dims(y, -1)\n",
    "    #y = tf.tile(y, [1, output_size])\n",
    "    #x = tf.range(output_size,dtype=tf.int32)\n",
    "    #x = tf.expand_dims(x, 0)\n",
    "    #x = tf.tile(x, [output_size, 1])\n",
    "    xy_grid = tf.meshgrid(tf.range(output_size), tf.range(output_size))\n",
    "    xy_grid = tf.expand_dims(tf.stack(xy_grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
    "    xy_grid = tf.tile(tf.expand_dims(xy_grid, axis=0), [batch_size, 1, 1, 3, 1])\n",
    "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
    "    \n",
    "    #xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
    "    #xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
    "    #y_grid = tf.cast(xy_grid, tf.float32)\n",
    "\n",
    "    # Calculate the center position of the prediction box:\n",
    "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
    "    # Calculate the length and width of the prediction box:\n",
    "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
    "\n",
    "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
    "    pred_conf = tf.sigmoid(conv_raw_conf) # object box calculates the predicted confidence\n",
    "    pred_prob = tf.sigmoid(conv_raw_prob) # calculating the predicted probability category box object\n",
    "\n",
    "    # calculating the predicted probability category box object\n",
    "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
    "\n",
    "def Create_Yolo(input_size=416, channels=3, training=False, CLASSES=YOLO_COCO_CLASSES):\n",
    "    NUM_CLASS = len(read_class_names(CLASSES))\n",
    "    input_layer  = Input([input_size, input_size, channels])\n",
    "\n",
    "    if TRAIN_YOLO_TINY:\n",
    "        if YOLO_TYPE == \"yolov4\":\n",
    "            conv_tensors = YOLOv4_tiny(input_layer, NUM_CLASS)\n",
    "        if YOLO_TYPE == \"yolov3\":\n",
    "            conv_tensors = YOLOv3_tiny(input_layer, NUM_CLASS)\n",
    "    else:\n",
    "        if YOLO_TYPE == \"yolov4\":\n",
    "            conv_tensors = YOLOv4(input_layer, NUM_CLASS)\n",
    "        if YOLO_TYPE == \"yolov3\":\n",
    "            conv_tensors = YOLOv3(input_layer, NUM_CLASS)\n",
    "\n",
    "    output_tensors = []\n",
    "    for i, conv_tensor in enumerate(conv_tensors):\n",
    "        pred_tensor = decode(conv_tensor, NUM_CLASS, i)\n",
    "        if training: output_tensors.append(conv_tensor)\n",
    "        output_tensors.append(pred_tensor)\n",
    "\n",
    "    Yolo = tf.keras.Model(input_layer, output_tensors)\n",
    "    return Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fddb473bcd0>"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo = Create_Yolo(input_size=224, CLASSES=TRAIN_CLASSES)\n",
    "yolo.load_weights(f\"./checkpoints/clock/yolov4\") # use keras weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./clockNumData/test/21_clockDigit.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ID = 20\n",
    "label_txt = \"clockNumData/test.txt\"\n",
    "image_info = open(label_txt).readlines()[ID].split()\n",
    "image_path = image_info[0]\n",
    "print(image_path)\n",
    "image_path = \"./clockNumData/test.jpg\";\n",
    "img, bboxes = detect_image(yolo, image_path, \"txt.jpg\", input_size=224, show=False, \n",
    "                CLASSES=TRAIN_CLASSES, rectangle_colors=(125,0,0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([355.27255249, 219.93519592, 402.44171143, 265.37609863,\n",
       "          0.77413738,   3.        ]),\n",
       " array([334.47073364, 248.02484131, 378.67208862, 292.95367432,\n",
       "          0.74734962,   3.        ])]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_bboxes(bboxes[7:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 98.60335541, 137.19139099, 158.539505  , 187.32414246,\n",
       "          0.97983241,   2.        ]),\n",
       " array([382.35070801, 170.26812744, 431.93499756, 221.46089172,\n",
       "          0.9795084 ,   2.        ]),\n",
       " array([472.48959351, 234.7878418 , 513.22467041, 284.46759033,\n",
       "          0.95173472,   3.        ]),\n",
       " array([481.90454102, 336.00683594, 546.66687012, 386.7305603 ,\n",
       "          0.87056196,   4.        ]),\n",
       " array([335.2947998 , 440.54602051, 393.27661133, 490.92520142,\n",
       "          0.97631073,   6.        ]),\n",
       " array([236.93763733, 421.22338867, 277.3480835 , 470.97631836,\n",
       "          0.866777  ,   8.        ]),\n",
       " array([136.34143066, 400.07766724, 206.51570129, 450.96130371,\n",
       "          0.81497943,   9.        ]),\n",
       " array([451.71334839, 406.45391846, 488.9928894 , 456.90322876,\n",
       "          0.93461168,   5.        ]),\n",
       " array([279.39794922, 439.38763428, 315.99945068, 489.64691162,\n",
       "          0.95988834,   7.        ])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([355.27255249, 248.02484131, 378.67208862, 265.37609863,\n",
       "          0.77413738,   3.        ])]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rescaleImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_area(box):\n",
    "    return (box[3] - box[1]) * (box[2] - box[0])\n",
    "\n",
    "def overlap_box(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    if x2 > x1 and y2 > y1 and box1[5] == box2[5]:\n",
    "        return np.array([x1, y1, x2, y2, box1[4], box1[5]])\n",
    "    else:\n",
    "        return [0, 0, 0, 0, -1, -1]\n",
    "def outJoin_box(box1, box2):\n",
    "    x1 = min(box1[0], box2[0])\n",
    "    y1 = min(box1[1], box2[1])\n",
    "\n",
    "    x2 = max(box1[2], box2[2])\n",
    "    y2 = max(box1[3], box2[3])\n",
    "    return np.array([x1, y1, x2, y2, box1[4], box1[5]])\n",
    "\n",
    "def merge_bboxes(bboxes):\n",
    "    bboxesSize = len(bboxes) + 1\n",
    "    if bboxesSize <= 1:\n",
    "        return bboxes\n",
    "    while len(bboxes) < bboxesSize:\n",
    "        bboxesSize = len(bboxes)\n",
    "        overlapMatrix = np.zeros((bboxesSize, bboxesSize))\n",
    "        for i in range(bboxesSize - 1):\n",
    "            for j in range(i+1, bboxesSize):\n",
    "                overlapBox = overlap_box(bboxes[i], bboxes[j])\n",
    "                overlapA = box_area(overlapBox)\n",
    "                if overlapA < 0:\n",
    "                    continue\n",
    "                bA1 = box_area(bboxes[i])\n",
    "                bA2 = box_area(bboxes[j])\n",
    "                overlapP = max(overlapA / bA1, overlapA / bA2) \n",
    "                if  overlapP >= 0.8:\n",
    "                    overlapMatrix[i,j] = overlapP\n",
    "                if bboxes[i][5] != 1:\n",
    "                    overlapMatrix[i,j] = overlapP\n",
    "\n",
    "        idx = np.argmax(overlapMatrix)\n",
    "        rowI = idx // bboxesSize\n",
    "        colI = idx % bboxesSize\n",
    "        #print(bboxes)\n",
    "        if np.max(overlapMatrix) > 0.5:\n",
    "            #print(bboxes[rowI][5], bboxes[colI][5])\n",
    "            overlapBox = overlap_box(bboxes[rowI], bboxes[colI])\n",
    "            bboxes.pop(colI)\n",
    "            bboxes.pop(rowI)\n",
    "            bboxes.append(overlapBox)\n",
    "        if np.max(overlapMatrix) > 0.4:\n",
    "            #print(bboxes[rowI][5], bboxes[colI][5])\n",
    "            overlapBox = outJoin_box(bboxes[rowI], bboxes[colI])\n",
    "            bboxes.pop(colI)\n",
    "            bboxes.pop(rowI)\n",
    "            bboxes.append(overlapBox)\n",
    "\n",
    "        #print(bboxes[5:9])\n",
    "            \n",
    "    return bboxes\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rescale(data):\n",
    "    resultX = []\n",
    "    resultY = []\n",
    "    resultH = []\n",
    "    for stroke in data:\n",
    "        Xs = []\n",
    "        Ys = []\n",
    "        for key in stroke.keys():\n",
    "            for coor in stroke[key]:\n",
    "                Xs.append(coor['x'])\n",
    "                Ys.append(coor['y'])\n",
    "        if len(Xs) != 0:\n",
    "            resultX.append(Xs)\n",
    "            resultY.append(Ys)\n",
    "            resultH.append(max(Ys) - min(Ys))\n",
    "    minY = min([min(ele) for ele in resultY])\n",
    "    maxY = max([max(ele) for ele in resultY])\n",
    "    h = np.mean(resultH)\n",
    "    scale = 40 / 480 * (maxY - minY) / h\n",
    "    return scale\n",
    "\n",
    "def resacle_image(scale, image, ih, iw):\n",
    "    h,  w, _  = image.shape\n",
    "    scale = min(iw/w, ih/h)\n",
    "    nw, nh  = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "    image_paded = np.full(shape=[600, 600, 3], fill_value=255.0)\n",
    "    dw, dh = (600-nw)//2,( 600-nh)//2\n",
    "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
    "    image = image_paded\n",
    "    return image, dw, dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/app_data/clock_number.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "data = json.loads(data)\n",
    "data = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = get_rescale(data)\n",
    "ih, iw, _ = image.shape * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310.7194992390513"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./clockNumData/test.jpg\")\n",
    "ih, iw    = 377, 377\n",
    "h,  w, _  = image.shape\n",
    "#scale = min(iw/w, ih/h)\n",
    "nw, nh  = int(scale * w), int(scale * h)\n",
    "image_resized = cv2.resize(image, (nw, nh))\n",
    "image_paded = np.full(shape=[600, 600, 3], fill_value=255.0)\n",
    "dw, dh = 0,  0\n",
    "image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
    "image_paded = image_paded / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 599.5, 599.5, -0.5)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image_paded)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'math' has no attribute 'median'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/collin/Documents/GitHub/yolo4_written_number/detect.ipynb Cell 20'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/collin/Documents/GitHub/yolo4_written_number/detect.ipynb#ch0000019?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/collin/Documents/GitHub/yolo4_written_number/detect.ipynb#ch0000019?line=1'>2</a>\u001b[0m math\u001b[39m.\u001b[39;49mmedian([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'math' has no attribute 'median'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "math.median([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CDTenv1",
   "language": "python",
   "name": "cdtenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
